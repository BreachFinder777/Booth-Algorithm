{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAE7NigblhC0cVPn5vxf0K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BreachFinder777/Booth-Algorithm/blob/main/Android%20Malware.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlwQDvZcrRyE",
        "outputId": "da9fa0e5-db36-4bd8-81c3-94116283fade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANDROID MALWARE ANALYSIS PIPELINE\n",
            "============================================================\n",
            "Started at: 2025-06-20 16:42:31.475777\n",
            "STATIC ANALYSIS: ANDROID PERMISSIONS\n",
            "--------------------------------------------------\n",
            "Dataset loaded: 398 apps, 331 features\n",
            "\n",
            "Dataset Distribution:\n",
            "Benign apps (0): 199\n",
            "Malware apps (1): 199\n",
            "Balance ratio: 1.00 (Balanced)\n",
            "\n",
            "Permission Analysis:\n",
            "\n",
            "Top 10 permissions used by benign apps:\n",
            " 1. android.permission.WRITE_EXTERNAL_STORAGE: 76 apps\n",
            " 2. android.permission.ACCESS_NETWORK_STATE: 62 apps\n",
            " 3. android.permission.WAKE_LOCK: 36 apps\n",
            " 4. android.permission.RECEIVE_BOOT_COMPLETED: 30 apps\n",
            " 5. android.permission.ACCESS_WIFI_STATE: 29 apps\n",
            " 6. android.permission.READ_PHONE_STATE: 24 apps\n",
            " 7. android.permission.VIBRATE: 21 apps\n",
            " 8. android.permission.ACCESS_FINE_LOCATION: 18 apps\n",
            " 9. android.permission.READ_EXTERNAL_STORAGE: 15 apps\n",
            "10. android.permission.ACCESS_COARSE_LOCATION: 13 apps\n",
            "\n",
            "Top 10 permissions used by malware apps:\n",
            " 1. android.permission.INTERNET: 195 apps\n",
            " 2. android.permission.READ_PHONE_STATE: 190 apps\n",
            " 3. android.permission.ACCESS_NETWORK_STATE: 167 apps\n",
            " 4. android.permission.WRITE_EXTERNAL_STORAGE: 136 apps\n",
            " 5. android.permission.ACCESS_WIFI_STATE: 135 apps\n",
            " 6. android.permission.READ_SMS: 124 apps\n",
            " 7. android.permission.WRITE_SMS: 104 apps\n",
            " 8. android.permission.RECEIVE_BOOT_COMPLETED: 102 apps\n",
            " 9. android.permission.ACCESS_COARSE_LOCATION: 80 apps\n",
            "10. android.permission.CHANGE_WIFI_STATE: 75 apps\n",
            "Visualization saved as 'permission_analysis.png'\n",
            "\n",
            "Data Split:\n",
            "Training set: 318 samples\n",
            "Testing set: 80 samples\n",
            "\n",
            "TRAINING MODELS: STATIC ANALYSIS\n",
            "--------------------------------------------------\n",
            "\n",
            "Training Naive Bayes...\n",
            "\n",
            "Naive Bayes Results:\n",
            "Accuracy:  0.8250\n",
            "Precision: 0.8571\n",
            "Recall:    0.8250\n",
            "F1-Score:  0.8210\n",
            "Confusion Matrix:\n",
            "[[39  1]\n",
            " [13 27]]\n",
            "\n",
            "Training Decision Tree...\n",
            "\n",
            "Decision Tree Results:\n",
            "Accuracy:  0.9375\n",
            "Precision: 0.9400\n",
            "Recall:    0.9375\n",
            "F1-Score:  0.9374\n",
            "Confusion Matrix:\n",
            "[[36  4]\n",
            " [ 1 39]]\n",
            "\n",
            "Training Random Forest...\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy:  0.9500\n",
            "Precision: 0.9511\n",
            "Recall:    0.9500\n",
            "F1-Score:  0.9500\n",
            "Confusion Matrix:\n",
            "[[39  1]\n",
            " [ 3 37]]\n",
            "\n",
            "Training SVM...\n",
            "\n",
            "SVM Results:\n",
            "Accuracy:  0.9500\n",
            "Precision: 0.9511\n",
            "Recall:    0.9500\n",
            "F1-Score:  0.9500\n",
            "Confusion Matrix:\n",
            "[[37  3]\n",
            " [ 1 39]]\n",
            "\n",
            "Training KNN (k=6)...\n",
            "\n",
            "KNN (k=6) Results:\n",
            "Accuracy:  0.9250\n",
            "Precision: 0.9293\n",
            "Recall:    0.9250\n",
            "F1-Score:  0.9248\n",
            "Confusion Matrix:\n",
            "[[39  1]\n",
            " [ 5 35]]\n",
            "\n",
            "DYNAMIC ANALYSIS: NETWORK TRAFFIC\n",
            "--------------------------------------------------\n",
            "Dataset loaded: 7845 samples, 17 features\n",
            "\n",
            "Columns: ['name', 'tcp_packets', 'dist_port_tcp', 'external_ips', 'vulume_bytes', 'udp_packets', 'tcp_urg_packet', 'source_app_packets', 'remote_app_packets', 'source_app_bytes', 'remote_app_bytes', 'duracion', 'avg_local_pkt_rate', 'avg_remote_pkt_rate', 'source_app_packets.1', 'dns_query_times', 'type']\n",
            "\n",
            "Dataset Distribution:\n",
            "Benign samples: 4704\n",
            "Malware samples: 0\n",
            "\n",
            "Data Preprocessing:\n",
            "Missing values: 23535\n",
            "Columns with missing values: {'duracion': 7845, 'avg_local_pkt_rate': 7845, 'avg_remote_pkt_rate': 7845}\n",
            "Dropped columns: ['duracion', 'avg_local_pkt_rate', 'avg_remote_pkt_rate', 'tcp_urg_packet']\n",
            "Removed 1785 duplicate rows\n",
            "Removed 2 outliers from tcp_packets (threshold: 20000)\n",
            "Removed 2 outliers from dist_port_tcp (threshold: 1400)\n",
            "Removed 2 outliers from external_ips (threshold: 35)\n",
            "Removed 1 outliers from vulume_bytes (threshold: 2000000)\n",
            "Removed 3 outliers from udp_packets (threshold: 40)\n",
            "Removed 3 outliers from remote_app_packets (threshold: 15000)\n",
            "Removed duplicate column: source_app_packets.1\n",
            "Outlier removal: 6060 -> 6047 samples (13 removed)\n",
            "Final dataset shape: (6047, 12)\n",
            "Error in dynamic analysis: could not convert string to float: 'AntiVirus'\n",
            "Dynamic analysis failed - skipping dynamic models\n",
            "\n",
            "COMPARATIVE ANALYSIS\n",
            "============================================================\n",
            "\n",
            "STATIC ANALYSIS: PERMISSION-BASED\n",
            "--------------------------------------------------\n",
            "Best Model: Random Forest\n",
            "Accuracy: 0.9500\n",
            "\n",
            "All Models:\n",
            "Naive Bayes         : Accuracy = 0.8250, Precision = 0.8571, Recall = 0.8250, F1-Score = 0.8210\n",
            "Decision Tree       : Accuracy = 0.9375, Precision = 0.9400, Recall = 0.9375, F1-Score = 0.9374\n",
            "Random Forest       : Accuracy = 0.9500, Precision = 0.9511, Recall = 0.9500, F1-Score = 0.9500\n",
            "SVM                 : Accuracy = 0.9500, Precision = 0.9511, Recall = 0.9500, F1-Score = 0.9500\n",
            "KNN (k=6)           : Accuracy = 0.9250, Precision = 0.9293, Recall = 0.9250, F1-Score = 0.9248\n",
            "\n",
            "MODEL COMPARISON\n",
            "--------------------------------------------------\n",
            "\n",
            "ANALYSIS SUMMARY\n",
            "============================================================\n",
            "Completed successfully\n",
            "Analysis types: Static (Permissions), Dynamic (Network Traffic)\n",
            "Models evaluated: Naive Bayes, KNN, Decision Tree, Random Forest, SVM\n",
            "Completed at: 2025-06-20 16:42:41.313838\n"
          ]
        }
      ],
      "source": [
        "# Android Malware Analysis using Machine Learning\n",
        "# Author: Christian Camilo Urcuqui López (Modified and Enhanced)\n",
        "# Date: June 2025\n",
        "#\n",
        "# This script performs Android malware detection using two approaches:\n",
        "# 1. Static Analysis: Analyzing Android app permissions\n",
        "# 2. Dynamic Analysis: Analyzing network traffic patterns\n",
        "#\n",
        "# Datasets:\n",
        "# - Permissions: xwolf12/datasetandroidpermissions (train.csv)\n",
        "# - Network Traffic: xwolf12/network-traffic-android-malware (android_traffic.csv)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report, cohen_kappa_score\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import kagglehub\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(42)\n",
        "\n",
        "def load_datasets():\n",
        "    \"\"\"Download and return paths to the Kaggle datasets.\"\"\"\n",
        "    permissions_path = kagglehub.dataset_download('xwolf12/datasetandroidpermissions')\n",
        "    traffic_path = kagglehub.dataset_download('xwolf12/network-traffic-android-malware')\n",
        "\n",
        "    # Assume the files are named as in the notebook\n",
        "    static_data_path = os.path.join(permissions_path, 'train.csv')\n",
        "    dynamic_data_path = os.path.join(traffic_path, 'android_traffic.csv')\n",
        "\n",
        "    if not os.path.exists(static_data_path):\n",
        "        raise FileNotFoundError(f\"Static dataset not found at {static_data_path}\")\n",
        "    if not os.path.exists(dynamic_data_path):\n",
        "        raise FileNotFoundError(f\"Dynamic dataset not found at {dynamic_data_path}\")\n",
        "\n",
        "    return static_data_path, dynamic_data_path\n",
        "\n",
        "def perform_static_analysis(data_path):\n",
        "    \"\"\"\n",
        "    Perform static analysis on Android apps by analyzing their permissions.\n",
        "\n",
        "    Args:\n",
        "        data_path (str): Path to the permissions dataset CSV file\n",
        "\n",
        "    Returns:\n",
        "        tuple: Training and testing data splits, original DataFrame\n",
        "    \"\"\"\n",
        "    print(\"STATIC ANALYSIS: ANDROID PERMISSIONS\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(data_path, sep=\";\")\n",
        "        print(f\"Dataset loaded: {df.shape[0]} apps, {df.shape[1]} features\")\n",
        "\n",
        "        # Verify dataset structure\n",
        "        if 'type' not in df.columns or df.shape[1] < 2:\n",
        "            raise ValueError(\"Invalid dataset structure: 'type' column missing or insufficient features\")\n",
        "\n",
        "        # Convert to integer, handling non-numeric values\n",
        "        for col in df.columns:\n",
        "            if col != 'type':\n",
        "                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype('int64')\n",
        "\n",
        "        print(\"\\nDataset Distribution:\")\n",
        "        print(f\"Benign apps (0): {df['type'].value_counts().get(0, 0)}\")\n",
        "        print(f\"Malware apps (1): {df['type'].value_counts().get(1, 0)}\")\n",
        "        balance_ratio = min(df['type'].value_counts()) / max(df['type'].value_counts())\n",
        "        print(f\"Balance ratio: {balance_ratio:.2f} {'(Balanced)' if balance_ratio > 0.8 else '(Imbalanced)'}\\n\")\n",
        "\n",
        "        print(\"Permission Analysis:\")\n",
        "        benign_permissions = df[df['type'] == 0].sum(axis=0).sort_values(ascending=False)[1:11]\n",
        "        print(\"\\nTop 10 permissions used by benign apps:\")\n",
        "        for i, (perm, count) in enumerate(benign_permissions.items(), 1):\n",
        "            print(f\"{i:2d}. {perm}: {count} apps\")\n",
        "\n",
        "        malware_permissions = df[df['type'] == 1].sum(axis=0).sort_values(ascending=False)\n",
        "        malware_permissions = malware_permissions[malware_permissions.index != 'type'][:10]\n",
        "        print(\"\\nTop 10 permissions used by malware apps:\")\n",
        "        for i, (perm, count) in enumerate(malware_permissions.items(), 1):\n",
        "            print(f\"{i:2d}. {perm}: {count} apps\")\n",
        "\n",
        "        create_permission_visualization(df)\n",
        "\n",
        "        X = df.drop(columns=['type'])\n",
        "        y = df['type']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.20, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        print(\"\\nData Split:\")\n",
        "        print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "        print(f\"Testing set: {X_test.shape[0]} samples\")\n",
        "\n",
        "        return X_train, X_test, y_train, y_test, df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in static analysis: {str(e)}\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "def create_permission_visualization(df):\n",
        "    \"\"\"\n",
        "    Create visualizations comparing permission usage between malware and benign apps.\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): The permissions dataset\n",
        "    \"\"\"\n",
        "    try:\n",
        "        plt.style.use('seaborn-v0_8')\n",
        "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
        "\n",
        "        benign_top = df[df['type'] == 0].sum(axis=0).sort_values(ascending=False)[1:11]\n",
        "        benign_top.plot.bar(ax=ax1, color='green', alpha=0.7)\n",
        "        ax1.set_title('Top 10 Permissions - Benign Apps', fontsize=14, fontweight='bold')\n",
        "        ax1.set_ylabel('Number of Apps')\n",
        "        ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        malware_top = df[df['type'] == 1].sum(axis=0).sort_values(ascending=False)\n",
        "        malware_top = malware_top[malware_top.index != 'type'][:10]\n",
        "        malware_top.plot.bar(ax=ax2, color='red', alpha=0.7)\n",
        "        ax2.set_title('Top 10 Permissions - Malware Apps', fontsize=14, fontweight='bold')\n",
        "        ax2.set_ylabel('Number of Apps')\n",
        "        ax2.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('permission_analysis.png', dpi=300, bbox_inches='tight')\n",
        "        print(\"Visualization saved as 'permission_analysis.png'\")\n",
        "        plt.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Could not create visualization: {str(e)}\")\n",
        "\n",
        "def perform_dynamic_analysis(data_path):\n",
        "    \"\"\"\n",
        "    Perform dynamic analysis on Android apps by analyzing network traffic.\n",
        "\n",
        "    Args:\n",
        "        data_path (str): Path to the network traffic dataset CSV file\n",
        "\n",
        "    Returns:\n",
        "        tuple: Processed training and testing data splits, original DataFrame\n",
        "    \"\"\"\n",
        "    print(\"\\nDYNAMIC ANALYSIS: NETWORK TRAFFIC\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    try:\n",
        "        data = pd.read_csv(data_path, sep=\";\", encoding='latin1')\n",
        "        print(f\"Dataset loaded: {data.shape[0]} samples, {data.shape[1]} features\")\n",
        "        print(f\"\\nColumns: {list(data.columns)}\")\n",
        "\n",
        "        print(\"\\nDataset Distribution:\")\n",
        "        print(f\"Benign samples: {data['type'].value_counts().get('benign', 0)}\")\n",
        "        print(f\"Malware samples: {data['type'].value_counts().get('malware', 0)}\")\n",
        "\n",
        "        print(\"\\nData Preprocessing:\")\n",
        "        missing_values = data.isna().sum()\n",
        "        print(f\"Missing values: {missing_values.sum()}\")\n",
        "        if missing_values.sum() > 0:\n",
        "            print(f\"Columns with missing values: {missing_values[missing_values > 0].to_dict()}\")\n",
        "\n",
        "        columns_to_drop = []\n",
        "        for col in ['duracion', 'avg_local_pkt_rate', 'avg_remote_pkt_rate']:\n",
        "            if col in data.columns:\n",
        "                columns_to_drop.append(col)\n",
        "        if 'tcp_urg_packet' in data.columns and data['tcp_urg_packet'].sum() <= 2:\n",
        "            columns_to_drop.append('tcp_urg_packet')\n",
        "\n",
        "        if columns_to_drop:\n",
        "            data = data.drop(columns=columns_to_drop)\n",
        "            print(f\"Dropped columns: {columns_to_drop}\")\n",
        "\n",
        "        duplicates = data.duplicated().sum()\n",
        "        if duplicates > 0:\n",
        "            data = data.drop_duplicates()\n",
        "            print(f\"Removed {duplicates} duplicate rows\")\n",
        "\n",
        "        data = remove_outliers(data)\n",
        "        print(f\"Final dataset shape: {data.shape}\")\n",
        "\n",
        "        feature_columns = [col for col in data.columns if col != 'type']\n",
        "        X = data[feature_columns]\n",
        "        y = data['type'].astype(str)\n",
        "\n",
        "        scaler = RobustScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "        X_scaled = pd.DataFrame(X_scaled, columns=feature_columns)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_scaled, y, test_size=0.25, random_state=45, stratify=y\n",
        "        )\n",
        "\n",
        "        print(\"\\nData Split:\")\n",
        "        print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "        print(f\"Testing set: {X_test.shape[0]} samples\")\n",
        "\n",
        "        return X_train, X_test, y_train, y_test, data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in dynamic analysis: {str(e)}\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "def remove_outliers(data):\n",
        "    \"\"\"\n",
        "    Remove outliers from the dataset using statistical thresholds.\n",
        "\n",
        "    Args:\n",
        "        data (DataFrame): The dataset to clean\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: Cleaned dataset\n",
        "    \"\"\"\n",
        "    original_size = data.shape[0]\n",
        "    outlier_conditions = [\n",
        "        ('tcp_packets', 20000),\n",
        "        ('dist_port_tcp', 1400),\n",
        "        ('external_ips', 35),\n",
        "        ('vulume_bytes', 2000000),\n",
        "        ('udp_packets', 40),\n",
        "        ('remote_app_packets', 15000)\n",
        "    ]\n",
        "\n",
        "    for column, threshold in outlier_conditions:\n",
        "        if column in data.columns:\n",
        "            before_count = data.shape[0]\n",
        "            data = data[data[column] < threshold]\n",
        "            removed = before_count - data.shape[0]\n",
        "            if removed > 0:\n",
        "                print(f\"Removed {removed} outliers from {column} (threshold: {threshold})\")\n",
        "\n",
        "    if 'source_app_packets.1' in data.columns:\n",
        "        data = data.drop('source_app_packets.1', axis=1)\n",
        "        print(\"Removed duplicate column: source_app_packets.1\")\n",
        "\n",
        "    print(f\"Outlier removal: {original_size} -> {data.shape[0]} samples ({original_size - data.shape[0]} removed)\")\n",
        "    return data\n",
        "\n",
        "def train_static_models(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Train and evaluate machine learning models for static analysis.\n",
        "\n",
        "    Args:\n",
        "        X_train, X_test, y_train, y_test: Training and testing data splits\n",
        "\n",
        "    Returns:\n",
        "        dict: Model results\n",
        "    \"\"\"\n",
        "    print(\"\\nTRAINING MODELS: STATIC ANALYSIS\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    results = {}\n",
        "    models = [\n",
        "        ('Naive Bayes', GaussianNB()),\n",
        "        ('Decision Tree', DecisionTreeClassifier(random_state=42, max_depth=10)),\n",
        "        ('Random Forest', RandomForestClassifier(n_estimators=100, random_state=42, max_depth=15)),\n",
        "        ('SVM', SVC(kernel='rbf', random_state=42))\n",
        "    ]\n",
        "\n",
        "    best_k = 3\n",
        "    best_knn_score = 0\n",
        "\n",
        "    for k in range(3, 16, 3):\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        knn.fit(X_train, y_train)\n",
        "        pred_knn = knn.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, pred_knn)\n",
        "        if accuracy > best_knn_score:\n",
        "            best_knn_score = accuracy\n",
        "            best_k = k\n",
        "\n",
        "    models.append((f\"KNN (k={best_k})\", KNeighborsClassifier(n_neighbors=best_k)))\n",
        "\n",
        "    for name, model in models:\n",
        "        print(f\"\\nTraining {name}...\")\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        results[name] = evaluate_model(y_test, predictions, name)\n",
        "\n",
        "    return results\n",
        "\n",
        "def train_dynamic_models(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Train and evaluate machine learning models for dynamic analysis.\n",
        "\n",
        "    Args:\n",
        "        X_train, X_test, y_train, y_test: Training and testing data splits\n",
        "\n",
        "    Returns:\n",
        "        dict: Model results\n",
        "    \"\"\"\n",
        "    print(\"\\nTRAINING MODELS: DYNAMIC ANALYSIS\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    results = {}\n",
        "    models = [\n",
        "        ('Naive Bayes', GaussianNB()),\n",
        "        ('Random Forest', RandomForestClassifier(n_estimators=250, max_depth=50, random_state=45)),\n",
        "    ]\n",
        "\n",
        "    best_k = 3\n",
        "    best_knn_score = 0\n",
        "\n",
        "    for k in range(3, 16, 3):\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        knn.fit(X_train, y_train)\n",
        "        pred_knn = knn.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, pred_knn)\n",
        "        if accuracy > best_knn_score:\n",
        "            best_knn_score = accuracy\n",
        "            best_k = k\n",
        "\n",
        "    models.append((f\"KNN (k={best_k})\", KNeighborsClassifier(n_neighbors=best_k)))\n",
        "\n",
        "    for name, model in models:\n",
        "        print(f\"\\nTraining {name}...\")\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        results[name] = evaluate_model(y_test, predictions, name, use_kappa=True)\n",
        "\n",
        "        if name == 'Random Forest' and hasattr(model, 'feature_importances_'):\n",
        "            feature_names = X_train.columns\n",
        "            feature_importance = pd.DataFrame({\n",
        "                'feature': feature_names,\n",
        "                'importance': model.feature_importances_\n",
        "            }).sort_values('importance', ascending=False)\n",
        "            print(f\"\\nTop 5 Features (Random Forest):\")\n",
        "            for i, row in feature_importance.head().iterrows():\n",
        "                print(f\"{row['feature']}: {row['importance']:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def evaluate_model(y_true, y_pred, model_name, use_kappa=False):\n",
        "    \"\"\"\n",
        "    Evaluate a machine learning model's performance.\n",
        "\n",
        "    Args:\n",
        "        y_true: True labels\n",
        "        y_pred: Predicted labels\n",
        "        model_name (str): Name of the model\n",
        "        use_kappa (bool): Whether to include Cohen's Kappa score\n",
        "\n",
        "    Returns:\n",
        "        dict: Evaluation metrics\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall:    {recall:.4f}\")\n",
        "    print(f\"F1-Score:  {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "    if use_kappa:\n",
        "        kappa = cohen_kappa_score(y_true, y_pred)\n",
        "        print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
        "\n",
        "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1_score': f1, 'cohen_kappa': kappa if use_kappa else None}\n",
        "\n",
        "def compare_results(static_results, dynamic_results):\n",
        "    \"\"\"\n",
        "    Compare results from static and dynamic analysis.\n",
        "\n",
        "    Args:\n",
        "        static_results (dict): Results from static analysis models\n",
        "        dynamic_results (dict): Results from dynamic analysis models\n",
        "    \"\"\"\n",
        "    print(\"\\nCOMPARATIVE ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if static_results:\n",
        "        print(\"\\nSTATIC ANALYSIS: PERMISSION-BASED\")\n",
        "        print(\"-\" * 50)\n",
        "        best_static = max(static_results.items(), key=lambda x: x[1]['accuracy'])\n",
        "        print(f\"Best Model: {best_static[0]}\")\n",
        "        print(f\"Accuracy: {best_static[1]['accuracy']:.4f}\")\n",
        "        print(\"\\nAll Models:\")\n",
        "        for model, metrics in static_results.items():\n",
        "            print(f\"{model:20}: Accuracy = {metrics['accuracy']:.4f}, \"\n",
        "                  f\"Precision = {metrics['precision']:.4f}, \"\n",
        "                  f\"Recall = {metrics['recall']:.4f}, \"\n",
        "                  f\"F1-Score = {metrics['f1_score']:.4f}\")\n",
        "\n",
        "    if dynamic_results:\n",
        "        print(\"\\nDYNAMIC ANALYSIS: NETWORK TRAFFIC-BASED\")\n",
        "        print(\"-\" * 50)\n",
        "        best_dynamic = max(dynamic_results.items(), key=lambda x: x[1]['accuracy'])\n",
        "        print(f\"Best Model: {best_dynamic[0]}\")\n",
        "        print(f\"Accuracy: {best_dynamic[1]['accuracy']:.4f}\")\n",
        "        print(\"\\nAll Models:\")\n",
        "        for model, metrics in dynamic_results.items():\n",
        "            print(f\"{model:20}: Accuracy = {metrics['accuracy']:.4f}, \"\n",
        "                  f\"Precision = {metrics['precision']:.4f}, \"\n",
        "                  f\"Recall = {metrics['recall']:.4f}, \"\n",
        "                  f\"F1-Score = {metrics['f1_score']:.4f}, \"\n",
        "                  f\"Cohen's Kappa = {metrics['cohen_kappa']:.4f}\")\n",
        "\n",
        "    print(\"\\nMODEL COMPARISON\")\n",
        "    print(\"-\" * 50)\n",
        "    if static_results and dynamic_results:\n",
        "        print(f\"Best Static Model: {best_static[0]} (Accuracy: {best_static[1]['accuracy']:.4f})\")\n",
        "        print(f\"Best Dynamic Model: {best_dynamic[0]} (Accuracy: {best_dynamic[1]['accuracy']:.4f})\")\n",
        "        print(\"\\nRecommendation:\")\n",
        "        if best_static[1]['accuracy'] > best_dynamic[1]['accuracy']:\n",
        "            print(\"Static analysis performs better. Use permission-based features with \"\n",
        "                  f\"{best_static[0]} for optimal malware detection.\")\n",
        "        else:\n",
        "            print(\"Dynamic analysis performs better. Use network traffic-based features with \"\n",
        "                  f\"{best_dynamic[0]} for optimal malware detection.\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to execute the Android malware analysis pipeline.\n",
        "    \"\"\"\n",
        "    print(\"ANDROID MALWARE ANALYSIS PIPELINE\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Started at: {datetime.now()}\")\n",
        "\n",
        "    try:\n",
        "        static_data_path, dynamic_data_path = load_datasets()\n",
        "\n",
        "        static_data = perform_static_analysis(static_data_path)\n",
        "        static_results = None\n",
        "        if static_data[0] is not None:\n",
        "            X_train_static, X_test_static, y_train_static, y_test_static, df_static = static_data\n",
        "            static_results = train_static_models(X_train_static, X_test_static,\n",
        "                                              y_train_static, y_test_static)\n",
        "        else:\n",
        "            print(\"Static analysis failed - skipping static models\")\n",
        "\n",
        "        dynamic_data = perform_dynamic_analysis(dynamic_data_path)\n",
        "        dynamic_results = None\n",
        "        if dynamic_data[0] is not None:\n",
        "            X_train_dynamic, X_test_dynamic, y_train_dynamic, y_test_dynamic, df_dynamic = dynamic_data\n",
        "            dynamic_results = train_dynamic_models(X_train_dynamic, X_test_dynamic,\n",
        "                                                y_train_dynamic, y_test_dynamic)\n",
        "        else:\n",
        "            print(\"Dynamic analysis failed - skipping dynamic models\")\n",
        "\n",
        "        compare_results(static_results, dynamic_results)\n",
        "\n",
        "        print(\"\\nANALYSIS SUMMARY\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"Completed successfully\")\n",
        "        print(\"Analysis types: Static (Permissions), Dynamic (Network Traffic)\")\n",
        "        print(\"Models evaluated: Naive Bayes, KNN, Decision Tree, Random Forest, SVM\")\n",
        "        print(f\"Completed at: {datetime.now()}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in execution: {str(e)}\")\n",
        "        print(\"Please verify dataset availability and Kaggle API credentials.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        import matplotlib\n",
        "        matplotlib.use('Agg')\n",
        "    except:\n",
        "        pass\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Android Malware Analysis using Machine Learning\n",
        "# Author: Christian Camilo Urcuqui López (Modified and Enhanced)\n",
        "# Date: June 2025\n",
        "#\n",
        "# This script performs Android malware detection using two approaches:\n",
        "# 1. Static Analysis: Analyzing Android app permissions\n",
        "# 2. Dynamic Analysis: Analyzing network traffic patterns\n",
        "#\n",
        "# Datasets:\n",
        "# - Permissions: xwolf12/datasetandroidpermissions (train.csv)\n",
        "# - Network Traffic: xwolf12/network-traffic-android-malware (android_traffic.csv)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, cohen_kappa_score\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import kagglehub\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(42)\n",
        "\n",
        "# Visualization Functions\n",
        "def plot_class_distribution(y, title, save_path):\n",
        "    counts = y.value_counts()\n",
        "    labels = counts.index\n",
        "    if all(isinstance(label, (int, float)) for label in labels):\n",
        "        labels = ['Benign' if label == 0 else 'Malware' for label in labels]\n",
        "    else:\n",
        "        labels = [label.capitalize() for label in labels]\n",
        "    plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90)\n",
        "    plt.title(title)\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "def plot_feature_importance(feature_importance, title, save_path, top_n=10):\n",
        "    feature_importance = feature_importance.sort_values('importance', ascending=False).head(top_n)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x='importance', y='feature', data=feature_importance)\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "def plot_correlation_heatmap(X, title, save_path):\n",
        "    corr = X.corr()\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(corr, cmap='coolwarm', center=0, annot=False)\n",
        "    plt.title(title)\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "def plot_boxplots(data, columns, title, save_path):\n",
        "    if not columns:\n",
        "        return\n",
        "    n_cols = min(len(columns), 4)\n",
        "    fig, axes = plt.subplots(1, n_cols, figsize=(5 * n_cols, 5))\n",
        "    if n_cols == 1:\n",
        "        axes = [axes]\n",
        "    for ax, col in zip(axes, columns):\n",
        "        sns.boxplot(y=data[col], ax=ax)\n",
        "        ax.set_title(col)\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "def plot_model_comparison(results, metric, title, save_path):\n",
        "    models = list(results.keys())\n",
        "    values = [results[model][metric] for model in models]\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=models, y=values)\n",
        "    plt.title(title)\n",
        "    plt.ylabel(metric.capitalize())\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(cm, y_true, title, save_path):\n",
        "    labels = sorted(set(y_true))\n",
        "    if labels == [0,1]:\n",
        "        display_labels = ['Benign', 'Malware']\n",
        "    else:\n",
        "        display_labels = [label.capitalize() for label in labels]\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=display_labels, yticklabels=display_labels)\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "def load_datasets():\n",
        "    \"\"\"Download and return paths to the Kaggle datasets.\"\"\"\n",
        "    permissions_path = kagglehub.dataset_download('xwolf12/datasetandroidpermissions')\n",
        "    traffic_path = kagglehub.dataset_download('xwolf12/network-traffic-android-malware')\n",
        "\n",
        "    static_data_path = os.path.join(permissions_path, 'train.csv')\n",
        "    dynamic_data_path = os.path.join(traffic_path, 'android_traffic.csv')\n",
        "\n",
        "    if not os.path.exists(static_data_path):\n",
        "        raise FileNotFoundError(f\"Static dataset not found at {static_data_path}\")\n",
        "    if not os.path.exists(dynamic_data_path):\n",
        "        raise FileNotFoundError(f\"Dynamic dataset not found at {dynamic_data_path}\")\n",
        "\n",
        "    return static_data_path, dynamic_data_path\n",
        "\n",
        "def perform_static_analysis(data_path):\n",
        "    print(\"STATIC ANALYSIS: ANDROID PERMISSIONS\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(data_path, sep=\";\")\n",
        "        print(f\"Dataset loaded: {df.shape[0]} apps, {df.shape[1]} features\")\n",
        "\n",
        "        if 'type' not in df.columns or df.shape[1] < 2:\n",
        "            raise ValueError(\"Invalid dataset structure: 'type' column missing or insufficient features\")\n",
        "\n",
        "        for col in df.columns:\n",
        "            if col != 'type':\n",
        "                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype('int64')\n",
        "\n",
        "        print(\"\\nDataset Distribution:\")\n",
        "        print(f\"Benign apps (0): {df['type'].value_counts().get(0, 0)}\")\n",
        "        print(f\"Malware apps (1): {df['type'].value_counts().get(1, 0)}\")\n",
        "        balance_ratio = min(df['type'].value_counts()) / max(df['type'].value_counts())\n",
        "        print(f\"Balance ratio: {balance_ratio:.2f} {'(Balanced)' if balance_ratio > 0.8 else '(Imbalanced)'}\\n\")\n",
        "\n",
        "        # Plot class distribution\n",
        "        plot_class_distribution(df['type'], 'Static Analysis Class Distribution', 'static_class_distribution.png')\n",
        "\n",
        "        print(\"Permission Analysis:\")\n",
        "        benign_permissions = df[df['type'] == 0].sum(axis=0).sort_values(ascending=False)[1:11]\n",
        "        print(\"\\nTop 10 permissions used by benign apps:\")\n",
        "        for i, (perm, count) in enumerate(benign_permissions.items(), 1):\n",
        "            print(f\"{i:2d}. {perm}: {count} apps\")\n",
        "\n",
        "        malware_permissions = df[df['type'] == 1].sum(axis=0).sort_values(ascending=False)\n",
        "        malware_permissions = malware_permissions[malware_permissions.index != 'type'][:10]\n",
        "        print(\"\\nTop 10 permissions used by malware apps:\")\n",
        "        for i, (perm, count) in enumerate(malware_permissions.items(), 1):\n",
        "            print(f\"{i:2d}. {perm}: {count} apps\")\n",
        "\n",
        "        create_permission_visualization(df)\n",
        "\n",
        "        X = df.drop(columns=['type'])\n",
        "        y = df['type']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.20, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        print(\"\\nData Split:\")\n",
        "        print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "        print(f\"Testing set: {X_test.shape[0]} samples\")\n",
        "\n",
        "        return X_train, X_test, y_train, y_test, df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in static analysis: {str(e)}\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "def create_permission_visualization(df):\n",
        "    try:\n",
        "        plt.style.use('seaborn-v0_8')\n",
        "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
        "\n",
        "        benign_top = df[df['type'] == 0].sum(axis=0).sort_values(ascending=False)[1:11]\n",
        "        benign_top.plot.bar(ax=ax1, color='green', alpha=0.7)\n",
        "        ax1.set_title('Top 10 Permissions - Benign Apps', fontsize=14, fontweight='bold')\n",
        "        ax1.set_ylabel('Number of Apps')\n",
        "        ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        malware_top = df[df['type'] == 1].sum(axis=0).sort_values(ascending=False)\n",
        "        malware_top = malware_top[malware_top.index != 'type'][:10]\n",
        "        malware_top.plot.bar(ax=ax2, color='red', alpha=0.7)\n",
        "        ax2.set_title('Top 10 Permissions - Malware Apps', fontsize=14, fontweight='bold')\n",
        "        ax2.set_ylabel('Number of Apps')\n",
        "        ax2.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('permission_analysis.png', dpi=300, bbox_inches='tight')\n",
        "        print(\"Visualization saved as 'permission_analysis.png'\")\n",
        "        plt.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Could not create visualization: {str(e)}\")\n",
        "\n",
        "def perform_dynamic_analysis(data_path):\n",
        "    print(\"\\nDYNAMIC ANALYSIS: NETWORK TRAFFIC\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    try:\n",
        "        data = pd.read_csv(data_path, sep=\";\", encoding='latin1')\n",
        "        print(f\"Dataset loaded: {data.shape[0]} samples, {data.shape[1]} features\")\n",
        "        print(f\"\\nColumns: {list(data.columns)}\")\n",
        "\n",
        "        print(\"\\nDataset Distribution:\")\n",
        "        print(f\"Benign samples: {data['type'].value_counts().get('benign', 0)}\")\n",
        "        print(f\"Malware samples: {data['type'].value_counts().get('malware', 0)}\")\n",
        "\n",
        "        # Plot class distribution\n",
        "        plot_class_distribution(data['type'], 'Dynamic Analysis Class Distribution', 'dynamic_class_distribution.png')\n",
        "\n",
        "        print(\"\\nData Preprocessing:\")\n",
        "        missing_values = data.isna().sum()\n",
        "        print(f\"Missing values: {missing_values.sum()}\")\n",
        "        if missing_values.sum() > 0:\n",
        "            print(f\"Columns with missing values: {missing_values[missing_values > 0].to_dict()}\")\n",
        "\n",
        "        columns_to_drop = []\n",
        "        for col in ['duracion', 'avg_local_pkt_rate', 'avg_remote_pkt_rate']:\n",
        "            if col in data.columns:\n",
        "                columns_to_drop.append(col)\n",
        "        if 'tcp_urg_packet' in data.columns and data['tcp_urg_packet'].sum() <= 2:\n",
        "            columns_to_drop.append('tcp_urg_packet')\n",
        "\n",
        "        if columns_to_drop:\n",
        "            data = data.drop(columns=columns_to_drop)\n",
        "            print(f\"Dropped columns: {columns_to_drop}\")\n",
        "\n",
        "        duplicates = data.duplicated().sum()\n",
        "        if duplicates > 0:\n",
        "            data = data.drop_duplicates()\n",
        "            print(f\"Removed {duplicates} duplicate rows\")\n",
        "\n",
        "        # Plot boxplots before outlier removal\n",
        "        outlier_columns = ['tcp_packets', 'dist_port_tcp', 'external_ips', 'vulume_bytes', 'udp_packets', 'remote_app_packets']\n",
        "        outlier_columns = [col for col in outlier_columns if col in data.columns]\n",
        "        if outlier_columns:\n",
        "            plot_boxplots(data, outlier_columns[:4], 'Dynamic Analysis: Before Outlier Removal', 'dynamic_before_outliers.png')\n",
        "\n",
        "        data = remove_outliers(data)\n",
        "        print(f\"Final dataset shape: {data.shape}\")\n",
        "\n",
        "        # Plot boxplots after outlier removal\n",
        "        if outlier_columns:\n",
        "            plot_boxplots(data, outlier_columns[:4], 'Dynamic Analysis: After Outlier Removal', 'dynamic_after_outliers.png')\n",
        "\n",
        "        feature_columns = [col for col in data.columns if col != 'type']\n",
        "        X = data[feature_columns].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
        "\n",
        "        # Plot correlation heatmap\n",
        "        plot_correlation_heatmap(X, 'Dynamic Analysis: Feature Correlation Heatmap', 'dynamic_correlation_heatmap.png')\n",
        "\n",
        "        y = data['type'].astype(str)\n",
        "\n",
        "        scaler = RobustScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "        X_scaled = pd.DataFrame(X_scaled, columns=feature_columns)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_scaled, y, test_size=0.25, random_state=45, stratify=y\n",
        "        )\n",
        "\n",
        "        print(\"\\nData Split:\")\n",
        "        print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "        print(f\"Testing set: {X_test.shape[0]} samples\")\n",
        "\n",
        "        return X_train, X_test, y_train, y_test, data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in dynamic analysis: {str(e)}\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "def remove_outliers(data):\n",
        "    original_size = data.shape[0]\n",
        "    outlier_conditions = [\n",
        "        ('tcp_packets', 20000),\n",
        "        ('dist_port_tcp', 1400),\n",
        "        ('external_ips', 35),\n",
        "        ('vulume_bytes', 2000000),\n",
        "        ('udp_packets', 40),\n",
        "        ('remote_app_packets', 15000)\n",
        "    ]\n",
        "\n",
        "    for column, threshold in outlier_conditions:\n",
        "        if column in data.columns:\n",
        "            before_count = data.shape[0]\n",
        "            data = data[data[column] < threshold]\n",
        "            removed = before_count - data.shape[0]\n",
        "            if removed > 0:\n",
        "                print(f\"Removed {removed} outliers from {column} (threshold: {threshold})\")\n",
        "\n",
        "    if 'source_app_packets.1' in data.columns:\n",
        "        data = data.drop('source_app_packets.1', axis=1)\n",
        "        print(\"Removed duplicate column: source_app_packets.1\")\n",
        "\n",
        "    print(f\"Outlier removal: {original_size} -> {data.shape[0]} samples ({original_size - data.shape[0]} removed)\")\n",
        "    return data\n",
        "\n",
        "def train_static_models(X_train, X_test, y_train, y_test):\n",
        "    print(\"\\nTRAINING MODELS: STATIC ANALYSIS\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Find best k for KNN\n",
        "    best_k = 3\n",
        "    best_knn_score = 0\n",
        "    for k in range(3, 16, 3):\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        knn.fit(X_train, y_train)\n",
        "        pred_knn = knn.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, pred_knn)\n",
        "        if accuracy > best_knn_score:\n",
        "            best_knn_score = accuracy\n",
        "            best_k = k\n",
        "\n",
        "    models = {\n",
        "        'Naive Bayes': GaussianNB(),\n",
        "        'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
        "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, max_depth=15),\n",
        "        'SVM': SVC(kernel='rbf', random_state=42),\n",
        "        f'KNN (k={best_k})': KNeighborsClassifier(n_neighbors=best_k)\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nTraining {name}...\")\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        results[name] = evaluate_model(y_test, predictions, name)\n",
        "\n",
        "        if name == 'Random Forest':\n",
        "            feature_importance = pd.DataFrame({\n",
        "                'feature': X_train.columns,\n",
        "                'importance': model.feature_importances_\n",
        "            })\n",
        "            plot_feature_importance(feature_importance, 'Static Analysis: Top 10 Important Permissions', 'static_feature_importance.png')\n",
        "\n",
        "    # Plot model comparison\n",
        "    plot_model_comparison(results, 'accuracy', 'Static Analysis: Model Accuracy Comparison', 'static_model_accuracy.png')\n",
        "\n",
        "    # Plot confusion matrix for best model\n",
        "    best_model_name = max(results, key=lambda k: results[k]['accuracy'])\n",
        "    best_model = models[best_model_name]\n",
        "    best_predictions = best_model.predict(X_test)\n",
        "    cm = confusion_matrix(y_test, best_predictions)\n",
        "    plot_confusion_matrix(cm, y_test, f'Static Analysis: Best Model ({best_model_name})', 'static_best_cm.png')\n",
        "\n",
        "    return results\n",
        "\n",
        "def train_dynamic_models(X_train, X_test, y_train, y_test):\n",
        "    print(\"\\nTRAINING MODELS: DYNAMIC ANALYSIS\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Find best k for KNN\n",
        "    best_k = 3\n",
        "    best_knn_score = 0\n",
        "    for k in range(3, 16, 3):\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        knn.fit(X_train, y_train)\n",
        "        pred_knn = knn.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, pred_knn)\n",
        "        if accuracy > best_knn_score:\n",
        "            best_knn_score = accuracy\n",
        "            best_k = k\n",
        "\n",
        "    models = {\n",
        "        'Naive Bayes': GaussianNB(),\n",
        "        'Random Forest': RandomForestClassifier(n_estimators=250, max_depth=50, random_state=45),\n",
        "        f'KNN (k={best_k})': KNeighborsClassifier(n_neighbors=best_k)\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nTraining {name}...\")\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        results[name] = evaluate_model(y_test, predictions, name, use_kappa=True)\n",
        "\n",
        "        if name == 'Random Forest':\n",
        "            feature_importance = pd.DataFrame({\n",
        "                'feature': X_train.columns,\n",
        "                'importance': model.feature_importances_\n",
        "            })\n",
        "            plot_feature_importance(feature_importance, 'Dynamic Analysis: Top 10 Important Features', 'dynamic_feature_importance.png')\n",
        "\n",
        "    # Plot model comparison\n",
        "    plot_model_comparison(results, 'accuracy', 'Dynamic Analysis: Model Accuracy Comparison', 'dynamic_model_accuracy.png')\n",
        "\n",
        "    # Plot confusion matrix for best model\n",
        "    best_model_name = max(results, key=lambda k: results[k]['accuracy'])\n",
        "    best_model = models[best_model_name]\n",
        "    best_predictions = best_model.predict(X_test)\n",
        "    cm = confusion_matrix(y_test, best_predictions)\n",
        "    plot_confusion_matrix(cm, y_test, f'Dynamic Analysis: Best Model ({best_model_name})', 'dynamic_best_cm.png')\n",
        "\n",
        "    return results\n",
        "\n",
        "def evaluate_model(y_true, y_pred, model_name, use_kappa=False):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall:    {recall:.4f}\")\n",
        "    print(f\"F1-Score:  {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "    kappa = None\n",
        "    if use_kappa:\n",
        "        kappa = cohen_kappa_score(y_true, y_pred)\n",
        "        print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
        "\n",
        "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1_score': f1, 'kappa': kappa}\n",
        "\n",
        "def compare_results(static_results, dynamic_results):\n",
        "    print(\"\\nCOMPARATIVE ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if static_results:\n",
        "        print(\"\\nSTATIC ANALYSIS: PERMISSION-BASED\")\n",
        "        print(\"-\" * 50)\n",
        "        best_static = max(static_results.items(), key=lambda x: x[1]['accuracy'])\n",
        "        print(f\"Best Model: {best_static[0]}\")\n",
        "        print(f\"Accuracy: {best_static[1]['accuracy']:.4f}\")\n",
        "        print(\"\\nAll Models:\")\n",
        "        for model, metrics in static_results.items():\n",
        "            print(f\"{model:20}: Accuracy = {metrics['accuracy']:.4f}, \"\n",
        "                  f\"Precision = {metrics['precision']:.4f}, \"\n",
        "                  f\"Recall = {metrics['recall']:.4f}, \"\n",
        "                  f\"F1-Score = {metrics['f1_score']:.4f}\")\n",
        "\n",
        "    if dynamic_results:\n",
        "        print(\"\\nDYNAMIC ANALYSIS: NETWORK TRAFFIC-BASED\")\n",
        "        print(\"-\" * 50)\n",
        "        best_dynamic = max(dynamic_results.items(), key=lambda x: x[1]['accuracy'])\n",
        "        print(f\"Best Model: {best_dynamic[0]}\")\n",
        "        print(f\"Accuracy: {best_dynamic[1]['accuracy']:.4f}\")\n",
        "        print(\"\\nAll Models:\")\n",
        "        for model, metrics in dynamic_results.items():\n",
        "            print(f\"{model:20}: Accuracy = {metrics['accuracy']:.4f}, \"\n",
        "                  f\"Precision = {metrics['precision']:.4f}, \"\n",
        "                  f\"Recall = {metrics['recall']:.4f}, \"\n",
        "                  f\"F1-Score = {metrics['f1_score']:.4f}, \"\n",
        "                  f\"Cohen's Kappa = {metrics['kappa']:.4f}\")\n",
        "\n",
        "    print(\"\\nMODEL COMPARISON\")\n",
        "    print(\"-\" * 50)\n",
        "    if static_results and dynamic_results:\n",
        "        print(f\"Best Static Model: {best_static[0]} (Accuracy: {best_static[1]['accuracy']:.4f})\")\n",
        "        print(f\"Best Dynamic Model: {best_dynamic[0]} (Accuracy: {best_dynamic[1]['accuracy']:.4f})\")\n",
        "        print(\"\\nRecommendation:\")\n",
        "        if best_static[1]['accuracy'] > best_dynamic[1]['accuracy']:\n",
        "            print(\"Static analysis performs better. Use permission-based features with \"\n",
        "                  f\"{best_static[0]} for optimal malware detection.\")\n",
        "        else:\n",
        "            print(\"Dynamic analysis performs better. Use network traffic-based features with \"\n",
        "                  f\"{best_dynamic[0]} for optimal malware detection.\")\n",
        "\n",
        "def main():\n",
        "    print(\"ANDROID MALWARE ANALYSIS PIPELINE\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Started at: {datetime.now()}\")\n",
        "\n",
        "    try:\n",
        "        static_data_path, dynamic_data_path = load_datasets()\n",
        "\n",
        "        static_data = perform_static_analysis(static_data_path)\n",
        "        static_results = None\n",
        "        if static_data[0] is not None:\n",
        "            X_train_static, X_test_static, y_train_static, y_test_static, df_static = static_data\n",
        "            static_results = train_static_models(X_train_static, X_test_static,\n",
        "                                              y_train_static, y_test_static)\n",
        "        else:\n",
        "            print(\"Static analysis failed - skipping static models\")\n",
        "\n",
        "        dynamic_data = perform_dynamic_analysis(dynamic_data_path)\n",
        "        dynamic_results = None\n",
        "        if dynamic_data[0] is not None:\n",
        "            X_train_dynamic, X_test_dynamic, y_train_dynamic, y_test_dynamic, df_dynamic = dynamic_data\n",
        "            dynamic_results = train_dynamic_models(X_train_dynamic, X_test_dynamic,\n",
        "                                                y_train_dynamic, y_test_dynamic)\n",
        "        else:\n",
        "            print(\"Dynamic analysis failed - skipping dynamic models\")\n",
        "\n",
        "        compare_results(static_results, dynamic_results)\n",
        "\n",
        "        print(\"\\nANALYSIS SUMMARY\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"Completed successfully\")\n",
        "        print(\"Analysis types: Static (Permissions), Dynamic (Network Traffic)\")\n",
        "        print(\"Models evaluated: Naive Bayes, KNN, Decision Tree, Random Forest, SVM\")\n",
        "        print(f\"Completed at: {datetime.now()}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in execution: {str(e)}\")\n",
        "        print(\"Please verify dataset availability and Kaggle API credentials.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        import matplotlib\n",
        "        matplotlib.use('Agg')\n",
        "    except:\n",
        "        pass\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TVJndOTtU9k",
        "outputId": "18889b68-cf5b-4e6b-99e6-86cec75056da"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANDROID MALWARE ANALYSIS PIPELINE\n",
            "============================================================\n",
            "Started at: 2025-06-20 16:41:37.082929\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/xwolf12/datasetandroidpermissions?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.03k/9.03k [00:00<00:00, 14.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/xwolf12/network-traffic-android-malware?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 114k/114k [00:00<00:00, 54.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "STATIC ANALYSIS: ANDROID PERMISSIONS\n",
            "--------------------------------------------------\n",
            "Dataset loaded: 398 apps, 331 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Distribution:\n",
            "Benign apps (0): 199\n",
            "Malware apps (1): 199\n",
            "Balance ratio: 1.00 (Balanced)\n",
            "\n",
            "Permission Analysis:\n",
            "\n",
            "Top 10 permissions used by benign apps:\n",
            " 1. android.permission.WRITE_EXTERNAL_STORAGE: 76 apps\n",
            " 2. android.permission.ACCESS_NETWORK_STATE: 62 apps\n",
            " 3. android.permission.WAKE_LOCK: 36 apps\n",
            " 4. android.permission.RECEIVE_BOOT_COMPLETED: 30 apps\n",
            " 5. android.permission.ACCESS_WIFI_STATE: 29 apps\n",
            " 6. android.permission.READ_PHONE_STATE: 24 apps\n",
            " 7. android.permission.VIBRATE: 21 apps\n",
            " 8. android.permission.ACCESS_FINE_LOCATION: 18 apps\n",
            " 9. android.permission.READ_EXTERNAL_STORAGE: 15 apps\n",
            "10. android.permission.ACCESS_COARSE_LOCATION: 13 apps\n",
            "\n",
            "Top 10 permissions used by malware apps:\n",
            " 1. android.permission.INTERNET: 195 apps\n",
            " 2. android.permission.READ_PHONE_STATE: 190 apps\n",
            " 3. android.permission.ACCESS_NETWORK_STATE: 167 apps\n",
            " 4. android.permission.WRITE_EXTERNAL_STORAGE: 136 apps\n",
            " 5. android.permission.ACCESS_WIFI_STATE: 135 apps\n",
            " 6. android.permission.READ_SMS: 124 apps\n",
            " 7. android.permission.WRITE_SMS: 104 apps\n",
            " 8. android.permission.RECEIVE_BOOT_COMPLETED: 102 apps\n",
            " 9. android.permission.ACCESS_COARSE_LOCATION: 80 apps\n",
            "10. android.permission.CHANGE_WIFI_STATE: 75 apps\n",
            "Visualization saved as 'permission_analysis.png'\n",
            "\n",
            "Data Split:\n",
            "Training set: 318 samples\n",
            "Testing set: 80 samples\n",
            "\n",
            "TRAINING MODELS: STATIC ANALYSIS\n",
            "--------------------------------------------------\n",
            "\n",
            "Training Naive Bayes...\n",
            "\n",
            "Naive Bayes Results:\n",
            "Accuracy:  0.8250\n",
            "Precision: 0.8571\n",
            "Recall:    0.8250\n",
            "F1-Score:  0.8210\n",
            "Confusion Matrix:\n",
            "[[39  1]\n",
            " [13 27]]\n",
            "\n",
            "Training Decision Tree...\n",
            "\n",
            "Decision Tree Results:\n",
            "Accuracy:  0.9375\n",
            "Precision: 0.9400\n",
            "Recall:    0.9375\n",
            "F1-Score:  0.9374\n",
            "Confusion Matrix:\n",
            "[[36  4]\n",
            " [ 1 39]]\n",
            "\n",
            "Training Random Forest...\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy:  0.9500\n",
            "Precision: 0.9511\n",
            "Recall:    0.9500\n",
            "F1-Score:  0.9500\n",
            "Confusion Matrix:\n",
            "[[39  1]\n",
            " [ 3 37]]\n",
            "\n",
            "Training SVM...\n",
            "\n",
            "SVM Results:\n",
            "Accuracy:  0.9500\n",
            "Precision: 0.9511\n",
            "Recall:    0.9500\n",
            "F1-Score:  0.9500\n",
            "Confusion Matrix:\n",
            "[[37  3]\n",
            " [ 1 39]]\n",
            "\n",
            "Training KNN (k=6)...\n",
            "\n",
            "KNN (k=6) Results:\n",
            "Accuracy:  0.9250\n",
            "Precision: 0.9293\n",
            "Recall:    0.9250\n",
            "F1-Score:  0.9248\n",
            "Confusion Matrix:\n",
            "[[39  1]\n",
            " [ 5 35]]\n",
            "\n",
            "DYNAMIC ANALYSIS: NETWORK TRAFFIC\n",
            "--------------------------------------------------\n",
            "Dataset loaded: 7845 samples, 17 features\n",
            "\n",
            "Columns: ['name', 'tcp_packets', 'dist_port_tcp', 'external_ips', 'vulume_bytes', 'udp_packets', 'tcp_urg_packet', 'source_app_packets', 'remote_app_packets', 'source_app_bytes', 'remote_app_bytes', 'duracion', 'avg_local_pkt_rate', 'avg_remote_pkt_rate', 'source_app_packets.1', 'dns_query_times', 'type']\n",
            "\n",
            "Dataset Distribution:\n",
            "Benign samples: 4704\n",
            "Malware samples: 0\n",
            "\n",
            "Data Preprocessing:\n",
            "Missing values: 23535\n",
            "Columns with missing values: {'duracion': 7845, 'avg_local_pkt_rate': 7845, 'avg_remote_pkt_rate': 7845}\n",
            "Dropped columns: ['duracion', 'avg_local_pkt_rate', 'avg_remote_pkt_rate', 'tcp_urg_packet']\n",
            "Removed 1785 duplicate rows\n",
            "Removed 2 outliers from tcp_packets (threshold: 20000)\n",
            "Removed 2 outliers from dist_port_tcp (threshold: 1400)\n",
            "Removed 2 outliers from external_ips (threshold: 35)\n",
            "Removed 1 outliers from vulume_bytes (threshold: 2000000)\n",
            "Removed 3 outliers from udp_packets (threshold: 40)\n",
            "Removed 3 outliers from remote_app_packets (threshold: 15000)\n",
            "Removed duplicate column: source_app_packets.1\n",
            "Outlier removal: 6060 -> 6047 samples (13 removed)\n",
            "Final dataset shape: (6047, 12)\n",
            "\n",
            "Data Split:\n",
            "Training set: 4535 samples\n",
            "Testing set: 1512 samples\n",
            "\n",
            "TRAINING MODELS: DYNAMIC ANALYSIS\n",
            "--------------------------------------------------\n",
            "\n",
            "Training Naive Bayes...\n",
            "\n",
            "Naive Bayes Results:\n",
            "Accuracy:  0.3538\n",
            "Precision: 0.6253\n",
            "Recall:    0.3538\n",
            "F1-Score:  0.2607\n",
            "Confusion Matrix:\n",
            "[[ 97 947]\n",
            " [ 30 438]]\n",
            "Cohen's Kappa: 0.0187\n",
            "\n",
            "Training Random Forest...\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy:  0.8618\n",
            "Precision: 0.8601\n",
            "Recall:    0.8618\n",
            "F1-Score:  0.8606\n",
            "Confusion Matrix:\n",
            "[[953  91]\n",
            " [118 350]]\n",
            "Cohen's Kappa: 0.6714\n",
            "\n",
            "Training KNN (k=3)...\n",
            "\n",
            "KNN (k=3) Results:\n",
            "Accuracy:  0.8307\n",
            "Precision: 0.8313\n",
            "Recall:    0.8307\n",
            "F1-Score:  0.8310\n",
            "Confusion Matrix:\n",
            "[[913 131]\n",
            " [125 343]]\n",
            "Cohen's Kappa: 0.6053\n",
            "\n",
            "COMPARATIVE ANALYSIS\n",
            "============================================================\n",
            "\n",
            "STATIC ANALYSIS: PERMISSION-BASED\n",
            "--------------------------------------------------\n",
            "Best Model: Random Forest\n",
            "Accuracy: 0.9500\n",
            "\n",
            "All Models:\n",
            "Naive Bayes         : Accuracy = 0.8250, Precision = 0.8571, Recall = 0.8250, F1-Score = 0.8210\n",
            "Decision Tree       : Accuracy = 0.9375, Precision = 0.9400, Recall = 0.9375, F1-Score = 0.9374\n",
            "Random Forest       : Accuracy = 0.9500, Precision = 0.9511, Recall = 0.9500, F1-Score = 0.9500\n",
            "SVM                 : Accuracy = 0.9500, Precision = 0.9511, Recall = 0.9500, F1-Score = 0.9500\n",
            "KNN (k=6)           : Accuracy = 0.9250, Precision = 0.9293, Recall = 0.9250, F1-Score = 0.9248\n",
            "\n",
            "DYNAMIC ANALYSIS: NETWORK TRAFFIC-BASED\n",
            "--------------------------------------------------\n",
            "Best Model: Random Forest\n",
            "Accuracy: 0.8618\n",
            "\n",
            "All Models:\n",
            "Naive Bayes         : Accuracy = 0.3538, Precision = 0.6253, Recall = 0.3538, F1-Score = 0.2607, Cohen's Kappa = 0.0187\n",
            "Random Forest       : Accuracy = 0.8618, Precision = 0.8601, Recall = 0.8618, F1-Score = 0.8606, Cohen's Kappa = 0.6714\n",
            "KNN (k=3)           : Accuracy = 0.8307, Precision = 0.8313, Recall = 0.8307, F1-Score = 0.8310, Cohen's Kappa = 0.6053\n",
            "\n",
            "MODEL COMPARISON\n",
            "--------------------------------------------------\n",
            "Best Static Model: Random Forest (Accuracy: 0.9500)\n",
            "Best Dynamic Model: Random Forest (Accuracy: 0.8618)\n",
            "\n",
            "Recommendation:\n",
            "Static analysis performs better. Use permission-based features with Random Forest for optimal malware detection.\n",
            "\n",
            "ANALYSIS SUMMARY\n",
            "============================================================\n",
            "Completed successfully\n",
            "Analysis types: Static (Permissions), Dynamic (Network Traffic)\n",
            "Models evaluated: Naive Bayes, KNN, Decision Tree, Random Forest, SVM\n",
            "Completed at: 2025-06-20 16:42:31.410892\n"
          ]
        }
      ]
    }
  ]
}